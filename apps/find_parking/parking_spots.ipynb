{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Ollama\n",
    "from langchain.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = Ollama(model = \"llama3\")\n",
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "filePath = \"parking_spots.csv\"\n",
    "\n",
    "loader = CSVLoader(file_path=filePath)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "t_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "\n",
    "splits = t_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "presist_directory = \"docs/chroma/\"\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents= splits, \n",
    "    embedding= embedding,\n",
    "    persist_directory= presist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding= embedding\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Retreival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"get me empty nomal parking near to lift\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vectordb.similarity_search(question)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "indexResult = index.query(question, llm=llm)\n",
    "display(Markdown(indexResult))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm, \n",
    "    retriever=index.vectorstore.as_retriever(search_kwargs={\"k\": 5}), \n",
    "    return_source_documents=True,\n",
    "    return_generated_question=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Looking for Empty parking\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Looking for VIP Empty parking which is near to lift on floor 1\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Looking for VIP Empty parking which is near to lift\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Looking for Normal Empty parking which is near to lift\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Looking for Empty parking which is near to lift\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"find parking spots floor 2 and 3 near to lift\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mUse the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 256\n",
      "Parking Status: Empty\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Stairs\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 911\n",
      "Parking Status: Empty\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Door\n",
      "\n",
      "Floor: 3\n",
      "Parking Number: 4\n",
      "Parking Status: Empty\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Stairs\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 420\n",
      "Parking Status: Empty\n",
      "Parking Type: Normal\n",
      "Metadata: Right Corner\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 750\n",
      "Parking Status: Empty\n",
      "Parking Type: Normal\n",
      "Metadata: Right Corner\n",
      "\n",
      "Question: Before answring the question sort data by floor and sort the answer by parking number, How many empty parking available on 1st Floor?\n",
      "Helpful Answer:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Before answering the question, I will sort the data by floor. Here is the sorted data:\n",
       "\n",
       "**Floor 1**\n",
       "\n",
       "* Parking Number: 256, Parking Status: Empty, Parking Type: VIP, Metadata: Near to Stairs\n",
       "* Parking Number: 420, Parking Status: Empty, Parking Type: Normal, Metadata: Right Corner\n",
       "* Parking Number: 750, Parking Status: Empty, Parking Type: Normal, Metadata: Right Corner\n",
       "* Parking Number: 911, Parking Status: Empty, Parking Type: VIP, Metadata: Near to Door\n",
       "\n",
       "Now, I will sort the answer by parking number. Here are the results:\n",
       "\n",
       "There are 4 empty parking available on 1st Floor."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Before answring the question sort data by floor and sort the answer by parking number, How many empty parking available on 1st Floor?\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
