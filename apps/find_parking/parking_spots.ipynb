{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model = \"llama3\")\n",
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "file_path = \"parking_spots.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Floor  Parking Number Parking Status  Parking Type      Metadata\n",
      "1       1               2         Filled  Special Need  Near to Door\n",
      "42      1              43          Empty           VIP   Left Corner\n",
      "43      1              44          Empty  Special Need  Near to Door\n",
      "45      1              46          Empty  Special Need  Near to Door\n",
      "46      1              47         Filled           VIP  Near to Door\n",
      "Total empty parking spots on the 1st floor: 89\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the CSV file using pandas for data inspection\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Sort data by floor and parking number\n",
    "df_sorted = df.sort_values(by=['Floor', 'Parking Number'])\n",
    "\n",
    "# Check the first few rows to confirm sorting\n",
    "print(df_sorted.head())\n",
    "\n",
    "# Count empty parking spots on the 1st floor\n",
    "first_floor_empty = df_sorted[(df_sorted['Floor'] == 1) & (df_sorted['Parking Status'] == 'Empty')]\n",
    "total_empty_first_floor = len(first_floor_empty)\n",
    "print(f\"Total empty parking spots on the 1st floor: {total_empty_first_floor}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sorted data back to a CSV file\n",
    "sorted_file_path = \"sorted_parking_spots.csv\"\n",
    "df_sorted.to_csv(sorted_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.runnables import (\n",
    "    Runnable,\n",
    "    RunnableLambda,\n",
    "    RunnableMap,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "@tool\n",
    "def empty_parking_byfloor(floor: str) -> int:\n",
    "    \"\"\"Fetch Empty Parking by Floor number\"\"\"\n",
    "    try:\n",
    "        _floor = int(floor)\n",
    "    except TypeError as e:\n",
    "        _floor = str(e)\n",
    "\n",
    "    first_floor_empty = df_sorted[(df_sorted['Floor'] == _floor) & (df_sorted['Parking Status'] == 'Empty')]\n",
    "    total_empty_first_floor = len(first_floor_empty)\n",
    "    print(total_empty_first_floor)\n",
    "    return total_empty_first_floor\n",
    "\n",
    "# tools = [empty_parking_byfloor]\n",
    "# llm_with_tools = llm.bind_tools(tools)\n",
    "# tool_map = {tool.name: tool for tool in tools}\n",
    "\n",
    "def call_tools(msg: AIMessage) -> Runnable:\n",
    "    \"\"\"Simple sequential tool calling helper.\"\"\"\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    tool_calls = msg.tool_calls.copy()\n",
    "    for tool_call in tool_calls:\n",
    "        tool_call[\"output\"] = tool_map[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "    return tool_calls\n",
    "\n",
    "\n",
    "from typing import List, Literal\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "    \n",
    "\n",
    "def router(state: List[BaseMessage]) -> Literal[\"empty_parking_byfloor\", \"__end__\"]:\n",
    "    last_message = state[-1]\n",
    "    tool_calls = last_message.tool_calls if isinstance(last_message, AIMessage) else []\n",
    "    if len(tool_calls):\n",
    "        return \"empty_parking_byfloor\"\n",
    "    else:\n",
    "        return \"__end__\"\n",
    "\n",
    "\n",
    "# model = ChatOllama(model=\"llama3\", temperature=0)\n",
    "model = OllamaFunctions(model=\"llama3\", temperature=0, format=\"json\")\n",
    "model_with_tools = model.bind_tools(\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"empty_parking_byfloor\",\n",
    "            \"description\": \"return fetch empty Parking by floor number\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"floor\": {\n",
    "                        \"type\": \"int\",\n",
    "                        \"description\": \"floor number, \" \"e.g. 1\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"floor\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call={\"name\": \"empty_parking_byfloor\"},\n",
    ")\n",
    "\n",
    "builder = MessageGraph()\n",
    "\n",
    "builder.add_node(\"oracle\", model_with_tools)\n",
    "\n",
    "tool_node = ToolNode([empty_parking_byfloor])\n",
    "builder.add_node(\"empty_parking_byfloor\", tool_node)\n",
    "\n",
    "builder.add_edge(\"empty_parking_byfloor\", END)\n",
    "builder.set_entry_point(\"oracle\")\n",
    "\n",
    "builder.add_conditional_edges(\"oracle\", router)\n",
    "runnable = builder.compile()\n",
    "\n",
    "output = runnable.invoke(\"fetch empty Parking by floor number 1\")\n",
    "print(output)\n",
    "\n",
    "# from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "# functions = [\n",
    "#     format_tool_to_openai_function(f) for f in [\n",
    "#         empty_parking_byfloor\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# llm = llm.bind(functions = functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = CSVLoader(file_path=sorted_file_path)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Floor: 1\\nParking Number: 2\\nParking Status: Filled\\nParking Type: Special Need\\nMetadata: Near to Door', metadata={'source': 'sorted_parking_spots.csv', 'row': 0}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 43\\nParking Status: Empty\\nParking Type: VIP\\nMetadata: Left Corner', metadata={'source': 'sorted_parking_spots.csv', 'row': 1}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 44\\nParking Status: Empty\\nParking Type: Special Need\\nMetadata: Near to Door', metadata={'source': 'sorted_parking_spots.csv', 'row': 2}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 46\\nParking Status: Empty\\nParking Type: Special Need\\nMetadata: Near to Door', metadata={'source': 'sorted_parking_spots.csv', 'row': 3}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 47\\nParking Status: Filled\\nParking Type: VIP\\nMetadata: Near to Door', metadata={'source': 'sorted_parking_spots.csv', 'row': 4}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 53\\nParking Status: Empty\\nParking Type: Normal\\nMetadata: Near to Door', metadata={'source': 'sorted_parking_spots.csv', 'row': 5}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 54\\nParking Status: Empty\\nParking Type: Special Need\\nMetadata: Left Corner', metadata={'source': 'sorted_parking_spots.csv', 'row': 6}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 55\\nParking Status: Empty\\nParking Type: VIP\\nMetadata: Right Corner', metadata={'source': 'sorted_parking_spots.csv', 'row': 7}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 59\\nParking Status: Empty\\nParking Type: Normal\\nMetadata: Near to Door', metadata={'source': 'sorted_parking_spots.csv', 'row': 8}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 71\\nParking Status: Filled\\nParking Type: VIP\\nMetadata: Near to Stairs', metadata={'source': 'sorted_parking_spots.csv', 'row': 9})]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "t_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "\n",
    "splits = t_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "presist_directory = \"docs/chroma/\"\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents= splits, \n",
    "    embedding= embedding,\n",
    "    persist_directory= presist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 2\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding= embedding\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Retreival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"get me empty nomal parking near to lift\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = vectordb.similarity_search(question)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "indexResult = index.query(question, llm=llm)\n",
    "display(Markdown(indexResult))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm, \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    return_source_documents=True,\n",
    "    return_generated_question=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# qa = RetrievalQA.from_chain_type(\n",
    "#     llm,\n",
    "#     retriever = vectordb.as_retriever(),\n",
    "#     chain_type = \"stuff\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = qa | runnable\n",
    "# chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Looking for Empty parking\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Looking for VIP Empty parking which is near to lift on floor 1\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Looking for VIP Empty parking which is near to lift\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Looking for Normal Empty parking which is near to lift\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Looking for Empty parking which is near to lift\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"find parking spots floor 2 and 3 near to lift\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many empty parking available on Floor 1?\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "# result\n",
    "# chain.invoke({\"role\":\"user\",\"content\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))\n",
    "# display(Markdown(result[\"result\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parking_byfloor(inputs: dict) -> dict:\n",
    "    \"\"\"Total Empty Parking Spots by Floor number\"\"\"\n",
    "    print(inputs)\n",
    "    # floor = inputs.get(\"floor\", \"\")\n",
    "    match = inputs #re.search(r'\\d+', floor)\n",
    "    if match:\n",
    "        _floor = int(match)\n",
    "    else:\n",
    "        raise ValueError(\"No valid floor number found in the input\")\n",
    "\n",
    "    first_floor_empty = df_sorted[(df_sorted['Floor'] == _floor) & (df_sorted['Parking Status'] == 'Empty')]\n",
    "    total_empty_first_floor = len(first_floor_empty)\n",
    "    return {\"answer\":str(total_empty_first_floor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "# Define the tool\n",
    "parking_tool = Tool(\n",
    "    name=\"ParkingByFloor\",\n",
    "    func=parking_byfloor,\n",
    "    description=\"Total number of empty parking spots by floor number\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = [parking_tool]\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm=llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    retriever=index.vectorstore.as_retriever(),\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_parking_by_floor_relevant(query):\n",
    "  # Define keywords/phrases related to parking by floor\n",
    "  keywords = [\"how many empty parking\"]\n",
    "  # Check for keywords in query or retrieved documents\n",
    "  for keyword in keywords:\n",
    "    if keyword in query.lower():\n",
    "      print(\"Matched\")\n",
    "      return True\n",
    "  return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_query(query):\n",
    "  # Analyze retrieved information or keywords in the query\n",
    "  if is_parking_by_floor_relevant(query.get(\"question\")):\n",
    "    # Call ParkingByFloor tool\n",
    "    return agent.run(query.get(\"question\"))\n",
    "  else:\n",
    "    # Use LLM for general conversation or other tools if defined\n",
    "    return qa(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How many empty parking available on floor 1?\" \n",
    "result = handle_query({\"question\": question, \"chat_history\":chat_history})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Looking for Empty parking which is near to lift\"\n",
    "result = handle_query({\"question\": question, \"chat_history\":chat_history})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
