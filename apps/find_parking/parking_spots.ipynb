{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain.embeddings import OllamaEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOllama(model = \"llama3\")\n",
    "embedding = OllamaEmbeddings(model=\"nomic-embed-text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "file_path = \"parking_spots.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Floor  Parking Number Parking Status  Parking Type      Metadata\n",
      "1       1               2         Filled  Special Need  Near to Door\n",
      "42      1              43          Empty           VIP   Left Corner\n",
      "43      1              44          Empty  Special Need  Near to Door\n",
      "45      1              46          Empty  Special Need  Near to Door\n",
      "46      1              47         Filled           VIP  Near to Door\n",
      "Total empty parking spots on the 1st floor: 89\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Load the CSV file using pandas for data inspection\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Sort data by floor and parking number\n",
    "df_sorted = df.sort_values(by=['Floor', 'Parking Number'])\n",
    "\n",
    "# Check the first few rows to confirm sorting\n",
    "print(df_sorted.head())\n",
    "\n",
    "# Count empty parking spots on the 1st floor\n",
    "first_floor_empty = df_sorted[(df_sorted['Floor'] == 1) & (df_sorted['Parking Status'] == 'Empty')]\n",
    "total_empty_first_floor = len(first_floor_empty)\n",
    "print(f\"Total empty parking spots on the 1st floor: {total_empty_first_floor}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sorted data back to a CSV file\n",
    "sorted_file_path = \"sorted_parking_spots.csv\"\n",
    "df_sorted.to_csv(sorted_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "[HumanMessage(content='fetch empty Parking by floor number 1', id='a0bb49af-388c-48c5-a909-58d2c6dacc07'), AIMessage(content='', id='run-f1ac4ac2-c38f-4417-b478-5e233e9547e8-0', tool_calls=[{'name': 'empty_parking_byfloor', 'args': {'floor': 1}, 'id': 'call_2dcb532e5cc740ed988e57e493f6648f'}]), ToolMessage(content='89', name='empty_parking_byfloor', id='b0780b1d-fa60-410e-b76e-b0056ffd1ec5', tool_call_id='call_2dcb532e5cc740ed988e57e493f6648f')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import AIMessage\n",
    "from langchain_core.runnables import (\n",
    "    Runnable,\n",
    "    RunnableLambda,\n",
    "    RunnableMap,\n",
    "    RunnablePassthrough,\n",
    ")\n",
    "\n",
    "@tool\n",
    "def empty_parking_byfloor(floor: str) -> int:\n",
    "    \"\"\"Fetch Empty Parking by Floor number\"\"\"\n",
    "    try:\n",
    "        _floor = int(floor)\n",
    "    except TypeError as e:\n",
    "        _floor = str(e)\n",
    "\n",
    "    first_floor_empty = df_sorted[(df_sorted['Floor'] == _floor) & (df_sorted['Parking Status'] == 'Empty')]\n",
    "    total_empty_first_floor = len(first_floor_empty)\n",
    "    print(total_empty_first_floor)\n",
    "    return total_empty_first_floor\n",
    "\n",
    "# tools = [empty_parking_byfloor]\n",
    "# llm_with_tools = llm.bind_tools(tools)\n",
    "# tool_map = {tool.name: tool for tool in tools}\n",
    "\n",
    "def call_tools(msg: AIMessage) -> Runnable:\n",
    "    \"\"\"Simple sequential tool calling helper.\"\"\"\n",
    "    tool_map = {tool.name: tool for tool in tools}\n",
    "    tool_calls = msg.tool_calls.copy()\n",
    "    for tool_call in tool_calls:\n",
    "        tool_call[\"output\"] = tool_map[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
    "    return tool_calls\n",
    "\n",
    "\n",
    "from typing import List, Literal\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.llms.ollama_functions import OllamaFunctions\n",
    "from langgraph.graph import END, MessageGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "    \n",
    "\n",
    "def router(state: List[BaseMessage]) -> Literal[\"empty_parking_byfloor\", \"__end__\"]:\n",
    "    last_message = state[-1]\n",
    "    tool_calls = last_message.tool_calls if isinstance(last_message, AIMessage) else []\n",
    "    if len(tool_calls):\n",
    "        return \"empty_parking_byfloor\"\n",
    "    else:\n",
    "        return \"__end__\"\n",
    "\n",
    "\n",
    "# model = ChatOllama(model=\"llama3\", temperature=0)\n",
    "model = OllamaFunctions(model=\"llama3\", temperature=0, format=\"json\")\n",
    "model_with_tools = model.bind_tools(\n",
    "    tools=[\n",
    "        {\n",
    "            \"name\": \"empty_parking_byfloor\",\n",
    "            \"description\": \"return fetch empty Parking by floor number\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"floor\": {\n",
    "                        \"type\": \"int\",\n",
    "                        \"description\": \"floor number, \" \"e.g. 1\",\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"floor\"],\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "    function_call={\"name\": \"empty_parking_byfloor\"},\n",
    ")\n",
    "\n",
    "builder = MessageGraph()\n",
    "\n",
    "builder.add_node(\"oracle\", model_with_tools)\n",
    "\n",
    "tool_node = ToolNode([empty_parking_byfloor])\n",
    "builder.add_node(\"empty_parking_byfloor\", tool_node)\n",
    "\n",
    "builder.add_edge(\"empty_parking_byfloor\", END)\n",
    "builder.set_entry_point(\"oracle\")\n",
    "\n",
    "builder.add_conditional_edges(\"oracle\", router)\n",
    "runnable = builder.compile()\n",
    "\n",
    "output = runnable.invoke(\"fetch empty Parking by floor number 1\")\n",
    "print(output)\n",
    "\n",
    "# from langchain.tools.render import format_tool_to_openai_function\n",
    "\n",
    "# functions = [\n",
    "#     format_tool_to_openai_function(f) for f in [\n",
    "#         empty_parking_byfloor\n",
    "#     ]\n",
    "# ]\n",
    "\n",
    "# llm = llm.bind(functions = functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = CSVLoader(file_path=sorted_file_path)\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Floor: 1\\nParking Number: 2\\nParking Status: Filled\\nParking Type: Special Need\\nMetadata: Near to Door', metadata={'source': 'sorted_parking_spots.csv', 'row': 0}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 43\\nParking Status: Empty\\nParking Type: VIP\\nMetadata: Left Corner', metadata={'source': 'sorted_parking_spots.csv', 'row': 1}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 44\\nParking Status: Empty\\nParking Type: Special Need\\nMetadata: Near to Door', metadata={'source': 'sorted_parking_spots.csv', 'row': 2}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 46\\nParking Status: Empty\\nParking Type: Special Need\\nMetadata: Near to Door', metadata={'source': 'sorted_parking_spots.csv', 'row': 3}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 47\\nParking Status: Filled\\nParking Type: VIP\\nMetadata: Near to Door', metadata={'source': 'sorted_parking_spots.csv', 'row': 4}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 53\\nParking Status: Empty\\nParking Type: Normal\\nMetadata: Near to Door', metadata={'source': 'sorted_parking_spots.csv', 'row': 5}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 54\\nParking Status: Empty\\nParking Type: Special Need\\nMetadata: Left Corner', metadata={'source': 'sorted_parking_spots.csv', 'row': 6}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 55\\nParking Status: Empty\\nParking Type: VIP\\nMetadata: Right Corner', metadata={'source': 'sorted_parking_spots.csv', 'row': 7}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 59\\nParking Status: Empty\\nParking Type: Normal\\nMetadata: Near to Door', metadata={'source': 'sorted_parking_spots.csv', 'row': 8}),\n",
       " Document(page_content='Floor: 1\\nParking Number: 71\\nParking Status: Filled\\nParking Type: VIP\\nMetadata: Near to Stairs', metadata={'source': 'sorted_parking_spots.csv', 'row': 9})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "t_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 100,\n",
    "    chunk_overlap = 0\n",
    ")\n",
    "\n",
    "splits = t_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "presist_directory = \"docs/chroma/\"\n",
    "\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents= splits, \n",
    "    embedding= embedding,\n",
    "    persist_directory= presist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iqbal/Iqbal/Study/Deeplearning.ai/Langchain/.venv/lib/python3.12/site-packages/pydantic/_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "# Method 2\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "\n",
    "index = VectorstoreIndexCreator(\n",
    "    vectorstore_cls=DocArrayInMemorySearch,\n",
    "    embedding= embedding\n",
    ").from_loaders([loader])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Retreival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"get me empty nomal parking near to lift\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='Floor: 2\\nParking Number: 517\\nParking Status: Empty\\nParking Type: Special Need\\nMetadata: Near to Lift', metadata={'row': 516, 'source': 'parking_spots.csv'}),\n",
       " Document(page_content='Floor: 2\\nParking Number: 517\\nParking Status: Empty\\nParking Type: Special Need\\nMetadata: Near to Lift', metadata={'row': 299, 'source': 'sorted_parking_spots.csv'}),\n",
       " Document(page_content='Floor: 2\\nParking Number: 517\\nParking Status: Empty\\nParking Type: Special Need\\nMetadata: Near to Lift', metadata={'row': 299, 'source': 'sorted_parking_spots.csv'}),\n",
       " Document(page_content='Floor: 2\\nParking Number: 517\\nParking Status: Empty\\nParking Type: Special Need\\nMetadata: Near to Lift', metadata={'row': 299, 'source': 'sorted_parking_spots.csv'})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = vectordb.similarity_search(question)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the given context, there are no normal parking slots available. However, I can suggest checking for available spots near the lift on floors 2 and 5.\n",
       "\n",
       "Here's what I found:\n",
       "\n",
       "* Floor 2: Parking Number 609 (Special Need) is empty.\n",
       "* Floor 5: Parking Number 606 (Special Need) is empty.\n",
       "\n",
       "If you're looking for a normal parking spot, I'm afraid there aren't any available near the lift. You may want to consider other options or ask for assistance from building management or staff."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "indexResult = index.query(question, llm=llm)\n",
    "display(Markdown(indexResult))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document QnA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "chat_history = []\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm, \n",
    "    retriever=index.vectorstore.as_retriever(), \n",
    "    return_source_documents=True,\n",
    "    return_generated_question=False,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# qa = RetrievalQA.from_chain_type(\n",
    "#     llm,\n",
    "#     retriever = vectordb.as_retriever(),\n",
    "#     chain_type = \"stuff\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = qa | runnable\n",
    "# chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iqbal/Iqbal/Study/Deeplearning.ai/Langchain/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Floor: 3\n",
      "Parking Number: 3\n",
      "Parking Status: Empty\n",
      "Parking Type: Special Need\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 3\n",
      "Parking Number: 70\n",
      "Parking Status: Empty\n",
      "Parking Type: Normal\n",
      "Metadata: Right Corner\n",
      "\n",
      "Floor: 5\n",
      "Parking Number: 60\n",
      "Parking Status: Empty\n",
      "Parking Type: Normal\n",
      "Metadata: Right Corner\n",
      "\n",
      "Floor: 3\n",
      "Parking Number: 872\n",
      "Parking Status: Empty\n",
      "Parking Type: Normal\n",
      "Metadata: Right Corner\n",
      "Human: Looking for Empty parking\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the provided context, I found a few empty parking spaces:\n",
       "\n",
       "1. Parking Number: 3 (Special Need) - Parking Status: Empty\n",
       "2. Parking Number: 70 (Normal) - Parking Status: Empty\n",
       "3. Parking Number: 60 (Normal) - Parking Status: Empty\n",
       "4. Parking Number: 872 (Normal) - Parking Status: Empty\n",
       "\n",
       "These parking spaces are located on Floor 3 and Floor 5, with the metadata indicating their locations near or at the right corner."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Looking for Empty parking\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Floor: 2\n",
      "Parking Number: 1000\n",
      "Parking Status: Empty\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 215\n",
      "Parking Status: Filled\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 698\n",
      "Parking Status: Filled\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 4\n",
      "Parking Number: 56\n",
      "Parking Status: Empty\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "Human: Looking for VIP Empty parking which is near to lift on floor 1\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "I can help you with that!\n",
       "\n",
       "According to the available information, there are two VIP empty parking spots on Floor 1 that are near the lift:\n",
       "\n",
       "* Parking Number: 1000 (Status: Empty)\n",
       "* Parking Number: 215 (Status: Empty)\n",
       "\n",
       "Please note that Parking Number 698 is already filled, so it's not an option for you."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Looking for VIP Empty parking which is near to lift on floor 1\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Floor: 4\n",
      "Parking Number: 56\n",
      "Parking Status: Empty\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 75\n",
      "Parking Status: Filled\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 4\n",
      "Parking Number: 80\n",
      "Parking Status: Empty\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 4\n",
      "Parking Number: 304\n",
      "Parking Status: Filled\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "Human: Looking for VIP Empty parking which is near to lift\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the provided context, I found a VIP empty parking spot that is near to a lift. The details are:\n",
       "\n",
       "* Floor: 4\n",
       "* Parking Number: 56\n",
       "* Parking Status: Empty\n",
       "* Parking Type: VIP\n",
       "* Metadata: Near to Lift\n",
       "\n",
       "This parking spot meets all your requirements!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Looking for VIP Empty parking which is near to lift\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Floor: 1\n",
      "Parking Number: 265\n",
      "Parking Status: Empty\n",
      "Parking Type: Normal\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 2\n",
      "Parking Number: 400\n",
      "Parking Status: Filled\n",
      "Parking Type: Normal\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 625\n",
      "Parking Status: Empty\n",
      "Parking Type: Normal\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 240\n",
      "Parking Status: Empty\n",
      "Parking Type: Normal\n",
      "Metadata: Near to Lift\n",
      "Human: Looking for Normal Empty parking which is near to lift\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the provided context, I can help you find a Normal Empty parking spot that is near to a lift.\n",
       "\n",
       "Let me scan through the information... Ah-ha! I found one!\n",
       "\n",
       "Parking Number: 265 (on Floor 1) and Parking Number: 240 (also on Floor 1) both have the status \"Empty\" and are classified as Normal parking. Additionally, they are labeled as being \"Near to Lift\".\n",
       "\n",
       "So, you can consider either of these two options!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Looking for Normal Empty parking which is near to lift\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Floor: 3\n",
      "Parking Number: 3\n",
      "Parking Status: Empty\n",
      "Parking Type: Special Need\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 4\n",
      "Parking Number: 304\n",
      "Parking Status: Filled\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 75\n",
      "Parking Status: Filled\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 2\n",
      "Parking Number: 1000\n",
      "Parking Status: Empty\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "Human: Looking for Empty parking which is near to lift\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "According to the context, I found an empty parking spot that is near to a lift. It's on Floor 3, Parking Number 3, and it's a Special Need parking type."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"Looking for Empty parking which is near to lift\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Floor: 4\n",
      "Parking Number: 304\n",
      "Parking Status: Filled\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 3\n",
      "Parking Number: 980\n",
      "Parking Status: Filled\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 4\n",
      "Parking Number: 900\n",
      "Parking Status: Filled\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 3\n",
      "Parking Number: 309\n",
      "Parking Status: Filled\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "Human: find parking spots floor 2 and 3 near to lift\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Based on the provided context, I can help you find parking spots on Floor 2 and 3 that are near to the lift. However, since there is no information about parking spots on those floors, I must conclude that none of the existing parking spots (which are all on Floor 4) meet your request.\n",
       "\n",
       "If you're looking for alternative solutions or would like me to assist you in finding parking spots on a different floor, please let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"find parking spots floor 2 and 3 near to lift\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Floor: 1\n",
      "Parking Number: 601\n",
      "Parking Status: Empty\n",
      "Parking Type: Normal\n",
      "Metadata: Left Corner\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 541\n",
      "Parking Status: Empty\n",
      "Parking Type: Normal\n",
      "Metadata: Left Corner\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 420\n",
      "Parking Status: Empty\n",
      "Parking Type: Normal\n",
      "Metadata: Right Corner\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 750\n",
      "Parking Status: Empty\n",
      "Parking Type: Normal\n",
      "Metadata: Right Corner\n",
      "Human: How many empty parking available on Floor 1?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "According to the context, there are 4 empty parking spaces available on Floor 1:\n",
       "\n",
       "* Parking Number: 601\n",
       "* Parking Number: 541\n",
       "* Parking Number: 420\n",
       "* Parking Number: 750\n",
       "\n",
       "All of these parking spaces have a \"Parking Status\" of \"Empty\", indicating that they are available for use."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "question = \"How many empty parking available on Floor 1?\"\n",
    "result = qa({\"question\": question, \"chat_history\":chat_history})\n",
    "# result\n",
    "# chain.invoke({\"role\":\"user\",\"content\": question, \"chat_history\":chat_history})\n",
    "display(Markdown(result[\"answer\"]))\n",
    "# display(Markdown(result[\"result\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parking_byfloor(inputs: dict) -> dict:\n",
    "    \"\"\"Total Empty Parking Spots by Floor number\"\"\"\n",
    "    print(inputs)\n",
    "    # floor = inputs.get(\"floor\", \"\")\n",
    "    match = inputs #re.search(r'\\d+', floor)\n",
    "    if match:\n",
    "        _floor = int(match)\n",
    "    else:\n",
    "        raise ValueError(\"No valid floor number found in the input\")\n",
    "\n",
    "    first_floor_empty = df_sorted[(df_sorted['Floor'] == _floor) & (df_sorted['Parking Status'] == 'Empty')]\n",
    "    total_empty_first_floor = len(first_floor_empty)\n",
    "    return {\"answer\":str(total_empty_first_floor)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, Tool\n",
    "\n",
    "# Define the tool\n",
    "parking_tool = Tool(\n",
    "    name=\"ParkingByFloor\",\n",
    "    func=parking_byfloor,\n",
    "    description=\"Total number of empty parking spots by floor number\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iqbal/Iqbal/Study/Deeplearning.ai/Langchain/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents import AgentType\n",
    "\n",
    "tools = [parking_tool]\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm=llm, \n",
    "    agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    retriever=index.vectorstore.as_retriever(),\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_parking_by_floor_relevant(query):\n",
    "  # Define keywords/phrases related to parking by floor\n",
    "  keywords = [\"how many empty parking\"]\n",
    "  # Check for keywords in query or retrieved documents\n",
    "  for keyword in keywords:\n",
    "    if keyword in query.lower():\n",
    "      print(\"Matched\")\n",
    "      return True\n",
    "  return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_query(query):\n",
    "  # Analyze retrieved information or keywords in the query\n",
    "  if is_parking_by_floor_relevant(query.get(\"question\")):\n",
    "    # Call ParkingByFloor tool\n",
    "    return agent.run(query.get(\"question\"))\n",
    "  else:\n",
    "    # Use LLM for general conversation or other tools if defined\n",
    "    return qa(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/iqbal/Iqbal/Study/Deeplearning.ai/Langchain/.venv/lib/python3.12/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: How can I find out how many empty parking spots are available on floor 1?\n",
      "\n",
      "Action:\n",
      "```json\n",
      "{\n",
      "  \"action\": \"ParkingByFloor\",\n",
      "  \"action_input\": {\"floor_number\": 1}\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m1\n",
      "\n",
      "Observation: \u001b[36;1m\u001b[1;3m{'answer': '89'}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer: 89\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "question = \"How many empty parking available on floor 1?\" \n",
    "result = handle_query({\"question\": question, \"chat_history\":chat_history})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: Use the following pieces of context to answer the user's question. \n",
      "If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
      "----------------\n",
      "Floor: 3\n",
      "Parking Number: 3\n",
      "Parking Status: Empty\n",
      "Parking Type: Special Need\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 4\n",
      "Parking Number: 304\n",
      "Parking Status: Filled\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 1\n",
      "Parking Number: 75\n",
      "Parking Status: Filled\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "\n",
      "Floor: 2\n",
      "Parking Number: 1000\n",
      "Parking Status: Empty\n",
      "Parking Type: VIP\n",
      "Metadata: Near to Lift\n",
      "Human: Looking for Empty parking which is near to lift\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Based on the provided context, I found an empty parking spot that is near to a lift. It's located on Floor 3 with Parking Number 3 and has a status of \"Empty\". Additionally, it's designated as a Special Need parking type, meaning it's designed for people with mobility issues.\n",
      "\n",
      "Here are the details:\n",
      "\n",
      "* Floor: 3\n",
      "* Parking Number: 3\n",
      "* Parking Status: Empty\n",
      "* Parking Type: Special Need\n",
      "* Metadata: Near to Lift\n"
     ]
    }
   ],
   "source": [
    "question = \"Looking for Empty parking which is near to lift\"\n",
    "result = handle_query({\"question\": question, \"chat_history\":chat_history})\n",
    "print(result[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
